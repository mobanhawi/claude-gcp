{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.587169Z",
     "start_time": "2025-12-31T05:18:23.578067Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.777556Z",
     "iopub.status.busy": "2026-01-09T02:45:45.777450Z",
     "iopub.status.idle": "2026-01-09T02:45:45.788109Z",
     "shell.execute_reply": "2026-01-09T02:45:45.787546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chunk by section\n",
    "import re\n",
    "\n",
    "\n",
    "def chunk_by_section(document_text):\n",
    "    pattern = r\"\\n## \"\n",
    "    return re.split(pattern, document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.597715Z",
     "start_time": "2025-12-31T05:18:23.587599Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.789895Z",
     "iopub.status.busy": "2026-01-09T02:45:45.789776Z",
     "iopub.status.idle": "2026-01-09T02:45:45.800560Z",
     "shell.execute_reply": "2026-01-09T02:45:45.799905Z"
    }
   },
   "outputs": [],
   "source": [
    "# BM25Index implementation\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import Callable, Optional, Any, List, Dict, Tuple\n",
    "\n",
    "\n",
    "class BM25Index:\n",
    "    def __init__(\n",
    "        self,\n",
    "        k1: float = 1.5,\n",
    "        b: float = 0.75,\n",
    "        tokenizer: Optional[Callable[[str], List[str]]] = None,\n",
    "    ):\n",
    "        self.documents: List[Dict[str, Any]] = []\n",
    "        self._corpus_tokens: List[List[str]] = []\n",
    "        self._doc_len: List[int] = []\n",
    "        self._doc_freqs: Dict[str, int] = {}\n",
    "        self._avg_doc_len: float = 0.0\n",
    "        self._idf: Dict[str, float] = {}\n",
    "        self._index_built: bool = False\n",
    "\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self._tokenizer = tokenizer if tokenizer else self._default_tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def _default_tokenizer(text: str) -> List[str]:\n",
    "        text = text.lower()\n",
    "        tokens = re.split(r\"\\W+\", text)\n",
    "        return [token for token in tokens if token]\n",
    "\n",
    "    def _update_stats_add(self, doc_tokens: List[str]):\n",
    "        self._doc_len.append(len(doc_tokens))\n",
    "\n",
    "        seen_in_doc = set()\n",
    "        for token in doc_tokens:\n",
    "            if token not in seen_in_doc:\n",
    "                self._doc_freqs[token] = self._doc_freqs.get(token, 0) + 1\n",
    "                seen_in_doc.add(token)\n",
    "\n",
    "        self._index_built = False\n",
    "\n",
    "    def _calculate_idf(self):\n",
    "        N = len(self.documents)\n",
    "        self._idf = {}\n",
    "        for term, freq in self._doc_freqs.items():\n",
    "            idf_score = math.log(((N - freq + 0.5) / (freq + 0.5)) + 1)\n",
    "            self._idf[term] = idf_score\n",
    "\n",
    "    def _build_index(self):\n",
    "        if not self.documents:\n",
    "            self._avg_doc_len = 0.0\n",
    "            self._idf = {}\n",
    "            self._index_built = True\n",
    "            return\n",
    "\n",
    "        self._avg_doc_len = sum(self._doc_len) / len(self.documents)\n",
    "        self._calculate_idf()\n",
    "        self._index_built = True\n",
    "\n",
    "    def add_document(self, document: Dict[str, Any]):\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\"Document dictionary must contain a 'content' key.\")\n",
    "\n",
    "        content = document.get(\"content\", \"\")\n",
    "        if not isinstance(content, str):\n",
    "            raise TypeError(\"Document 'content' must be a string.\")\n",
    "\n",
    "        doc_tokens = self._tokenizer(content)\n",
    "\n",
    "        self.documents.append(document)\n",
    "        self._corpus_tokens.append(doc_tokens)\n",
    "        self._update_stats_add(doc_tokens)\n",
    "\n",
    "    def _compute_bm25_score(self, query_tokens: List[str], doc_index: int) -> float:\n",
    "        score = 0.0\n",
    "        doc_term_counts = Counter(self._corpus_tokens[doc_index])\n",
    "        doc_length = self._doc_len[doc_index]\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token not in self._idf:\n",
    "                continue\n",
    "\n",
    "            idf = self._idf[token]\n",
    "            term_freq = doc_term_counts.get(token, 0)\n",
    "\n",
    "            numerator = idf * term_freq * (self.k1 + 1)\n",
    "            denominator = term_freq + self.k1 * (\n",
    "                1 - self.b + self.b * (doc_length / self._avg_doc_len)\n",
    "            )\n",
    "            score += numerator / (denominator + 1e-9)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query_text: str,\n",
    "        k: int = 1,\n",
    "        score_normalization_factor: float = 0.1,\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]:\n",
    "        if not self.documents:\n",
    "            return []\n",
    "\n",
    "        if not isinstance(query_text, str):\n",
    "            raise TypeError(\"Query text must be a string.\")\n",
    "\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "\n",
    "        if not self._index_built:\n",
    "            self._build_index()\n",
    "\n",
    "        if self._avg_doc_len == 0:\n",
    "            return []\n",
    "\n",
    "        query_tokens = self._tokenizer(query_text)\n",
    "        if not query_tokens:\n",
    "            return []\n",
    "\n",
    "        raw_scores = []\n",
    "        for i in range(len(self.documents)):\n",
    "            raw_score = self._compute_bm25_score(query_tokens, i)\n",
    "            if raw_score > 1e-9:\n",
    "                raw_scores.append((raw_score, self.documents[i]))\n",
    "\n",
    "        raw_scores.sort(key=lambda item: item[0], reverse=True)\n",
    "\n",
    "        normalized_results = []\n",
    "        for raw_score, doc in raw_scores[:k]:\n",
    "            normalized_score = math.exp(-score_normalization_factor * raw_score)\n",
    "            normalized_results.append((doc, normalized_score))\n",
    "\n",
    "        normalized_results.sort(key=lambda item: item[1])\n",
    "\n",
    "        return normalized_results\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.documents)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"BM25VectorStore(count={len(self)}, k1={self.k1}, b={self.b}, index_built={self._index_built})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.604243Z",
     "start_time": "2025-12-31T05:18:23.598227Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.802163Z",
     "iopub.status.busy": "2026-01-09T02:45:45.802049Z",
     "iopub.status.idle": "2026-01-09T02:45:45.805114Z",
     "shell.execute_reply": "2026-01-09T02:45:45.804679Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./report.md\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.608148Z",
     "start_time": "2025-12-31T05:18:23.604615Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.806452Z",
     "iopub.status.busy": "2026-01-09T02:45:45.806367Z",
     "iopub.status.idle": "2026-01-09T02:45:45.808101Z",
     "shell.execute_reply": "2026-01-09T02:45:45.807646Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Chunk the text by section\n",
    "chunks = chunk_by_section(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.613999Z",
     "start_time": "2025-12-31T05:18:23.608454Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.809513Z",
     "iopub.status.busy": "2026-01-09T02:45:45.809414Z",
     "iopub.status.idle": "2026-01-09T02:45:45.812418Z",
     "shell.execute_reply": "2026-01-09T02:45:45.811824Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Create a BM25 store and add each chunk to it\n",
    "bm25_store = BM25Index()\n",
    "for chunk in chunks:\n",
    "    bm25_store.add_document({\"content\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T05:18:23.627396Z",
     "start_time": "2025-12-31T05:18:23.614783Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-09T02:45:45.813750Z",
     "iopub.status.busy": "2026-01-09T02:45:45.813659Z",
     "iopub.status.idle": "2026-01-09T02:45:45.816247Z",
     "shell.execute_reply": "2026-01-09T02:45:45.815700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2730\n",
      "Content: Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improving the stability and performance of the core systems underpinning Project Phoenix. Recurring issues, particularly `ERR_MEM_ALLOC_FAIL_0x8007000E` during peak loads and `TIMEOUT_QUERY_DB_0xDEADBEEF` affecting data retrieval operations, were prioritized, at a cost of INC-2023-Q4-011. Root cause analysis pointed towards inefficiencies in the primary data caching algorithm and suboptimal database indexing strategies. The deployment of a patch addressed the memory allocation error, resulting in a measured 40% reduction in critical failures under simulated stress tests during Q4 2024 (Test Case ID: INC-2023-Q4-011). Further refactoring of the query module, scheduled for the next release cycle, aims to resolve the timeout issue. These findings underscore the importance of robust testing protocols, especially given the dependencies identified by the Product Engineering team (Section 6). The team continues to monitor system telemetry closely for any regressions or newly emerging error patterns. During Q4 of 2024 the team also assisted with helping regarding the INC-2023-Q4-011 incident.\n",
      "\n",
      "---\n",
      "\n",
      "Score: 0.3436\n",
      "Content: Section 10: Cybersecurity Analysis - Incident Response Report: INC-2023-Q4-011\n",
      "\n",
      "The Cybersecurity Operations Center successfully contained and remediated a targeted intrusion attempt tracked as `INC-2023-Q4-011`. Threat intelligence indicates the activity aligns with tactics, techniques, and procedures associated with the `ShadowNet Syndicate` threat actor group. Initial access was gained via a spear-phishing email targeting personnel within the finance department, potentially seeking data relevant to Section 3 (Financial Analysis). Endpoint detection and response (EDR) systems flagged anomalous process execution (`PID: 7812`) on workstation `WS-FIN-112`. Subsequent investigation identified malware (`SHA256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855`) attempting lateral movement towards server `SRV-FIN-03`. Containment involved isolating affected systems and blocking associated command-and-control infrastructure (IP `198.51.100.24`). Mitigation included deploying updated endpoint policies and implementing enhanced perimeter filtering (`Firewall Rule ID: FN7832`). This incident highlights the persistent threat landscape and the need for ongoing vigilance and user training, particularly concerning sensitive financial and potentially research data (e.g., Section 1, Section 9). Forensics analysis is ongoing.\n",
      "\n",
      "---\n",
      "\n",
      "Score: 0.9596\n",
      "Content: Section 4: Scientific Experimentation - Characterization of Material Composite XT-5\n",
      "\n",
      "The materials science team completed the initial characterization phase for Material Composite XT-5, a novel polymer-matrix composite developed in-house (Lab Ref: MSC-XT5-Batch007). Extensive testing focused on mechanical and thermal properties critical for potential next-generation applications. Results indicate a superior tensile strength averaging 450 ± 15 MPa, exceeding the benchmark material by approximately 18%. Thermal conductivity was measured at 0.8 ± 0.05 W/(m·K), suggesting suitability for applications requiring effective thermal management. However, preliminary fatigue testing (Cycle Count: 10^5 cycles, Stress Level: 200 MPa) revealed micro-fracturing patterns requiring further investigation. This approach to rigorous characterization is vital before considering integration into designs like those discussed in Section 6 (Product Engineering). The team is now focusing on optimizing the composite matrix formulation (Variant XT-5b) to enhance fatigue resistance while maintaining other desirable properties. These findings are promising but necessitate further validation.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Search the store\n",
    "results = bm25_store.search(\"What happened for INC-2023-Q4-011\", k=3)\n",
    "for doc, score in results:\n",
    "    print(f\"Score: {score:.4f}\\nContent: {doc['content']}\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
